{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Attribute Information:\n- ID number\n- Diagnosis (M = malignant, B = benign)\n- 32.Ten real-valued features are computed for each cell nucleus:\n    - radius (mean of distances from center to points on the perimeter)\n    - texture (standard deviation of gray-scale values)\n    - perimeter\n    - area\n    - smoothness (local variation in radius lengths)\n    - compactness (perimeter^2 / area - 1.0)\n    - concavity (severity of concave portions of the contour)\n    - concave points (number of concave portions of the contour)\n    - symmetry\n    - fractal dimension (\"coastline approximation\" - 1)\n    \nThe mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.","metadata":{}},{"cell_type":"markdown","source":"# Load Libraries ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.gridspec as grid\nimport mpld3 as mpl\n\n#Import models from scikit learn module:\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n# from sklearn.cross_validation import KFold   #For K-fold cross validation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.589779Z","iopub.execute_input":"2021-09-25T11:27:45.590380Z","iopub.status.idle":"2021-09-25T11:27:45.603709Z","shell.execute_reply.started":"2021-09-25T11:27:45.590325Z","shell.execute_reply":"2021-09-25T11:27:45.602423Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.605269Z","iopub.execute_input":"2021-09-25T11:27:45.605589Z","iopub.status.idle":"2021-09-25T11:27:45.616084Z","shell.execute_reply.started":"2021-09-25T11:27:45.605553Z","shell.execute_reply":"2021-09-25T11:27:45.615006Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Laoding the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv',header=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.619541Z","iopub.execute_input":"2021-09-25T11:27:45.620040Z","iopub.status.idle":"2021-09-25T11:27:45.637395Z","shell.execute_reply.started":"2021-09-25T11:27:45.619970Z","shell.execute_reply":"2021-09-25T11:27:45.636328Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.639450Z","iopub.execute_input":"2021-09-25T11:27:45.639817Z","iopub.status.idle":"2021-09-25T11:27:45.675166Z","shell.execute_reply.started":"2021-09-25T11:27:45.639768Z","shell.execute_reply":"2021-09-25T11:27:45.674103Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning and processing the dataset","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.677115Z","iopub.execute_input":"2021-09-25T11:27:45.677525Z","iopub.status.idle":"2021-09-25T11:27:45.684150Z","shell.execute_reply.started":"2021-09-25T11:27:45.677478Z","shell.execute_reply":"2021-09-25T11:27:45.683472Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"df.drop('id',axis =1,inplace =True)\ndf.drop('Unnamed: 32',axis =1,inplace =True)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.685618Z","iopub.execute_input":"2021-09-25T11:27:45.685918Z","iopub.status.idle":"2021-09-25T11:27:45.698626Z","shell.execute_reply.started":"2021-09-25T11:27:45.685870Z","shell.execute_reply":"2021-09-25T11:27:45.697538Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.700357Z","iopub.execute_input":"2021-09-25T11:27:45.700722Z","iopub.status.idle":"2021-09-25T11:27:45.735088Z","shell.execute_reply.started":"2021-09-25T11:27:45.700679Z","shell.execute_reply":"2021-09-25T11:27:45.733995Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"df.diagnosis.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.736587Z","iopub.execute_input":"2021-09-25T11:27:45.736944Z","iopub.status.idle":"2021-09-25T11:27:45.745117Z","shell.execute_reply.started":"2021-09-25T11:27:45.736913Z","shell.execute_reply":"2021-09-25T11:27:45.744322Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.747208Z","iopub.execute_input":"2021-09-25T11:27:45.747676Z","iopub.status.idle":"2021-09-25T11:27:45.755946Z","shell.execute_reply.started":"2021-09-25T11:27:45.747644Z","shell.execute_reply":"2021-09-25T11:27:45.754423Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.762848Z","iopub.execute_input":"2021-09-25T11:27:45.763216Z","iopub.status.idle":"2021-09-25T11:27:45.796921Z","shell.execute_reply.started":"2021-09-25T11:27:45.763177Z","shell.execute_reply":"2021-09-25T11:27:45.796180Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# EDA of the dataset","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.798482Z","iopub.execute_input":"2021-09-25T11:27:45.799288Z","iopub.status.idle":"2021-09-25T11:27:45.886925Z","shell.execute_reply.started":"2021-09-25T11:27:45.799239Z","shell.execute_reply":"2021-09-25T11:27:45.886193Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.888404Z","iopub.execute_input":"2021-09-25T11:27:45.889270Z","iopub.status.idle":"2021-09-25T11:27:45.905776Z","shell.execute_reply.started":"2021-09-25T11:27:45.889212Z","shell.execute_reply":"2021-09-25T11:27:45.904883Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"df.describe()\nplt.hist(df['diagnosis'])\nplt.title('Diagnosis (M=1 , B=0)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:45.907014Z","iopub.execute_input":"2021-09-25T11:27:45.907746Z","iopub.status.idle":"2021-09-25T11:27:46.203290Z","shell.execute_reply.started":"2021-09-25T11:27:45.907701Z","shell.execute_reply":"2021-09-25T11:27:46.202344Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"## Nucleus features vs diagnosis","metadata":{}},{"cell_type":"code","source":"features_mean=list(df.columns[1:11])\n# split dataframe into two based on diagnosis\ndfM=df[df['diagnosis'] ==1]\ndfB=df[df['diagnosis'] ==0]\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:46.206228Z","iopub.execute_input":"2021-09-25T11:27:46.206672Z","iopub.status.idle":"2021-09-25T11:27:46.215042Z","shell.execute_reply.started":"2021-09-25T11:27:46.206620Z","shell.execute_reply":"2021-09-25T11:27:46.213809Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#Stack the data\n# plt.rcParams.update({'font.size': 8})\nfig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8,10))\naxes = axes.ravel()\nfor idx,ax in enumerate(axes):\n    ax.figure\n    binwidth= (max(df[features_mean[idx]]) - min(df[features_mean[idx]]))/50\n    ax.hist([dfM[features_mean[idx]],dfB[features_mean[idx]]], bins=np.arange(min(df[features_mean[idx]]), max(df[features_mean[idx]]) + binwidth, binwidth) , density=True,alpha=0.5,histtype='bar',stacked=True,label=['M','B'],color=['b','g'])\n    ax.legend(loc='upper right')\n    ax.set_title(features_mean[idx])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:46.216767Z","iopub.execute_input":"2021-09-25T11:27:46.217133Z","iopub.status.idle":"2021-09-25T11:27:50.011247Z","shell.execute_reply.started":"2021-09-25T11:27:46.217087Z","shell.execute_reply":"2021-09-25T11:27:50.010190Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"# Observations\n- mean values of cell radius, perimeter, area, compactness, concavity and concave points can be used in classification of the cancer. Larger values of these parameters tends to show a correlation with malignant tumors.\n- mean values of texture, smoothness, symmetry or fractual dimension does not show a particular preference of one diagnosis over the other. In any of the histograms there are no noticeable large outliers that warrants further cleanup.","metadata":{}},{"cell_type":"markdown","source":"# Creating a test set and a training set\nSince this data set is not ordered, I am going to do a simple 70:30 split to create a training data set and a test data set.","metadata":{}},{"cell_type":"code","source":"trainX, testX = train_test_split(df, test_size = 0.3)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:50.012654Z","iopub.execute_input":"2021-09-25T11:27:50.012997Z","iopub.status.idle":"2021-09-25T11:27:50.021971Z","shell.execute_reply.started":"2021-09-25T11:27:50.012959Z","shell.execute_reply":"2021-09-25T11:27:50.020310Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"# Model Classification\nHere we are going to build a classification model and evaluate its performance using the training set.","metadata":{}},{"cell_type":"code","source":"#Generic function for making a classification model and accessing the performance\ndef classification_model(model,data,predictors,outcome):\n    #fit the model\n    model.fit(data[predictors],data[outcome])\n    \n    #make prediction on training set:\n    predictions = model.predict(data[predictors])\n    \n    #print accuracy\n    accuracy = metrics.accuracy_score(predictions,data[outcome])\n    print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n    \n    #perform k-fold cross-validation with 5 fold\n    kf = KFold(n_splits=5,shuffle=False)\n    error=[]\n    \n    for train, test in kf.split(trainX):\n        #Filter training data\n        train_predictors=(data[predictors].iloc[train,:])\n        \n        #the target we're using to train the algorithm.\n        train_target = data[outcome].iloc[train]\n        \n        #training the algorithm using the predictors and target\n        model.fit(train_predictors,train_target)\n        \n        #record error from each cross-validation run\n        error.append(model.score(data[predictors].iloc[test,:],data[outcome].iloc[test]))\n        \n        print(\"Cross- Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n        \n        # fit the model again so that it can be refered outside the function\n        model.fit(data[predictors],data[outcome])\n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:46:13.431616Z","iopub.execute_input":"2021-09-25T11:46:13.431992Z","iopub.status.idle":"2021-09-25T11:46:13.444359Z","shell.execute_reply.started":"2021-09-25T11:46:13.431959Z","shell.execute_reply":"2021-09-25T11:46:13.443224Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression model\nLogistic regression is widely used for classification of discrete data. In this case we will use it for binary (1,0) classification.\n\nBased on the observations in the histogram plots, we can reasonably hypothesize that the cancer diagnosis depends on the mean cell radius, mean perimeter, mean area, mean compactness, mean concavity and mean concave points. We can then perform a logistic regression analysis using those features as follows:","metadata":{}},{"cell_type":"code","source":"predictor_var = ['radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean']\noutcome_var = 'diagnosis'\nmodel= LogisticRegression()\nclassification_model(model,trainX,predictor_var,outcome_var)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:46:14.869836Z","iopub.execute_input":"2021-09-25T11:46:14.870660Z","iopub.status.idle":"2021-09-25T11:46:15.196704Z","shell.execute_reply.started":"2021-09-25T11:46:14.870605Z","shell.execute_reply":"2021-09-25T11:46:15.195655Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"The prediction accuracy is reasonable. What happens if we use just one predictor? Use the mean_radius:","metadata":{}},{"cell_type":"code","source":"predictor_var =['radius_mean']\nmodel = LogisticRegression()\nclassification_model(model,trainX,predictor_var,outcome_var)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:50.379703Z","iopub.execute_input":"2021-09-25T11:27:50.379947Z","iopub.status.idle":"2021-09-25T11:27:50.511592Z","shell.execute_reply.started":"2021-09-25T11:27:50.379905Z","shell.execute_reply":"2021-09-25T11:27:50.510543Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"This gives a similar prediction accuracy and a cross-validation score.\n\nThe accuracy of the predictions are good but not great. The cross-validation scores are reasonable. Can we do better with another model?","metadata":{}},{"cell_type":"markdown","source":"# Decision Tree Model","metadata":{}},{"cell_type":"code","source":"predictor_var = ['radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean']\nmodel = DecisionTreeClassifier()\nclassification_model(model,trainX,predictor_var,outcome_var)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:50.513325Z","iopub.execute_input":"2021-09-25T11:27:50.513746Z","iopub.status.idle":"2021-09-25T11:27:50.583203Z","shell.execute_reply.started":"2021-09-25T11:27:50.513699Z","shell.execute_reply":"2021-09-25T11:27:50.582143Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"### Here we are over-fitting the model probably due to the large number of predictors.\nLet use a single predictor, the obvious one is the radius of the cell.","metadata":{}},{"cell_type":"code","source":"predictor_var = ['radius_mean']\nmodel = DecisionTreeClassifier()\nclassification_model(model,trainX,predictor_var,outcome_var)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:50.584594Z","iopub.execute_input":"2021-09-25T11:27:50.585613Z","iopub.status.idle":"2021-09-25T11:27:50.637951Z","shell.execute_reply.started":"2021-09-25T11:27:50.585570Z","shell.execute_reply":"2021-09-25T11:27:50.637175Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"### The accuracy of the prediction is much much better here. But does it depend on the predictor?\n\nUsing a single predictor gives a 97% prediction accuracy for this model but the cross-validation score is not that great.","metadata":{}},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"predictor_var = features_mean\nmodel = RandomForestClassifier(n_estimators=100,min_samples_split=25,max_depth=7,max_features=2)\nclassification_model(model,trainX,predictor_var,outcome_var)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:50.639026Z","iopub.execute_input":"2021-09-25T11:27:50.639898Z","iopub.status.idle":"2021-09-25T11:27:52.926397Z","shell.execute_reply.started":"2021-09-25T11:27:50.639854Z","shell.execute_reply":"2021-09-25T11:27:52.925532Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"Using all the features improves the prediction accuracy and the cross-validation score is great.\n\nAn advantage with Random Forest is that it returns a feature importance matrix which can be used to select features. So lets select the top 5 features and use them as predictors.","metadata":{}},{"cell_type":"code","source":"featimp = pd.Series(model.feature_importances_,index=predictor_var).sort_values(ascending=False)\nprint(featimp)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:52.929772Z","iopub.execute_input":"2021-09-25T11:27:52.930070Z","iopub.status.idle":"2021-09-25T11:27:52.946248Z","shell.execute_reply.started":"2021-09-25T11:27:52.930039Z","shell.execute_reply":"2021-09-25T11:27:52.945321Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# using top 5 features\npredictor_var = ['concave points_mean','area_mean','radius_mean','perimeter_mean','concavity_mean']\nmodel = RandomForestClassifier(n_estimators=100,min_samples_split=25,max_depth=7,max_features=2)\nclassification_model(model,trainX,predictor_var,outcome_var)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:27:52.947551Z","iopub.execute_input":"2021-09-25T11:27:52.947861Z","iopub.status.idle":"2021-09-25T11:27:55.249512Z","shell.execute_reply.started":"2021-09-25T11:27:52.947824Z","shell.execute_reply":"2021-09-25T11:27:55.248465Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"Using the top 5 features only changes the prediction accuracy a bit but I think we get a better result if we use all the predictors.\n","metadata":{}},{"cell_type":"markdown","source":"# Model on the test dataset","metadata":{}},{"cell_type":"code","source":"testX.iloc[26]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:38:08.183715Z","iopub.execute_input":"2021-09-25T11:38:08.184062Z","iopub.status.idle":"2021-09-25T11:38:08.193158Z","shell.execute_reply.started":"2021-09-25T11:38:08.184027Z","shell.execute_reply":"2021-09-25T11:38:08.192198Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"testX.loc[26]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:38:21.324601Z","iopub.execute_input":"2021-09-25T11:38:21.325199Z","iopub.status.idle":"2021-09-25T11:38:21.335805Z","shell.execute_reply.started":"2021-09-25T11:38:21.325155Z","shell.execute_reply":"2021-09-25T11:38:21.334800Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# use all the features of the nucleus\npredictor_var = ['concave points_mean','area_mean','radius_mean','perimeter_mean','concavity_mean']\nmodel = RandomForestClassifier(n_estimators=100,min_samples_split=15,max_depth=7,max_features=2)\nclassification_model(model,testX,predictor_var,outcome_var)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:47:12.030513Z","iopub.execute_input":"2021-09-25T11:47:12.030882Z","iopub.status.idle":"2021-09-25T11:47:12.040214Z","shell.execute_reply.started":"2021-09-25T11:47:12.030841Z","shell.execute_reply":"2021-09-25T11:47:12.038915Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}